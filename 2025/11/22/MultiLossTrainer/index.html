<!DOCTYPE html>
<html lang="en">
    
    <head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover" name="viewport" />
    <meta name="description" content="å¦‚ä½•å®ç° MultiLossTrainer" />
    <meta name="hexo-theme-A4" content="v2.0.0" />
    <link rel="alternate icon" type="image/webp" href="/img/favicon.webp">
    <title>IamMI&#39;s Blogs</title>

    
        
<link rel="stylesheet" href="/css/highlight/style1.css">

        
<link rel="stylesheet" href="/css/reset.css">

        
<link rel="stylesheet" href="/css/markdown.css">

        
<link rel="stylesheet" href="/css/fonts.css">
 
         <!--æ³¨æ„ï¼šé¦–é¡µæ—¢ä¸æ˜¯postä¹Ÿä¸æ˜¯page-->
        
        
        
<link rel="stylesheet" href="/css/ui.css">
 
        
<link rel="stylesheet" href="/css/style.css">


        
            <!--è¿”å›é¡¶éƒ¨css-->
            
<link rel="stylesheet" href="/css/returnToTop.css">

            
<link rel="stylesheet" href="/css/unicons.css">

        
        
            <!--ç›®å½•-->
            
<link rel="stylesheet" href="/css/toc.css">

        
    

    
        
<link rel="stylesheet" href="/css/returnToLastPage.css">

    
    
   
<link rel="stylesheet" href="/css/lightgallery-bundle.min.css">


   
        
<link rel="stylesheet" href="/css/custom.css">

    
    <link rel='stylesheet' href='https://chinese-fonts-cdn.deno.dev/packages/lxgwwenkai/dist/LXGWWenKai-Regular/result.css' /> 
    <!-- Mermaid Support -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@9/dist/mermaid.min.js"></script>
    <script>
    mermaid.initialize({
        startOnLoad: true,
        theme: 'default'
    });
    </script>

<meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>
    
    
        <style>
            .index-main{
                max-width:  880px;
            }
        </style>

    
    



    

    
    




    
    


    <body>
        <script src="/js/darkmode-js.min.js"></script>
        
        <script>
            const options = {
                bottom: '40px', // default: '32px'
                right: 'unset', // default: '32px'
                left: '42px', // default: 'unset'
                time: '0.3s', // default: '0.3s'
                mixColor: '#fff', // default: '#fff'
                backgroundColor: ' #e4e4e4 ',  // default: '#fff'
                buttonColorDark: '#100f2c',  // default: '#100f2c'
                buttonColorLight: '#fff', // default: '#fff'
                saveInCookies: true, // default: true,
                label: 'ğŸŒ“', // default: ''
                autoMatchOsTheme: true // default: true
            }
            const darkmode = new Darkmode(options);
            darkmode.showWidget();
        </script>
        
        
            
                <div class="left-toc-container">
                    <nav id="toc" class="bs-docs-sidebar"></nav>
                </div>
            
        
        <div class="paper">

            

            
                <div class="shadow-drop-2-bottom paper-main">
                    


<div class="header">
    <div class="header-container">
        <style>
            .header-img {
                width: 56px;
                height: auto;
                object-fit: cover; /* ä¿æŒå›¾ç‰‡æ¯”ä¾‹ */
                transition: transform 0.3s ease-in-out; 
                border-radius: 0; 
            }
            
        </style>
        <img 
            alt="^-^" 
            cache-control="max-age=86400" 
            class="header-img" 
            src="/img/favicon.webp" 
        />
        <div class="header-content">
            <a class="logo" href="/">IamMI&#39;s Blogs</a> 
            <span class="description"></span> 
        </div>
    </div>
    
   
    <ul class="nav">
        
            
                <li><a href="/">é¦–é¡µ</a></li>
            
        
            
                <li><a href="/list/">æ–‡ç« </a></li>
            
        
            
                <li><a href="/about/">å…³äº</a></li>
            
        
            
                <li><a href="/tags/">æ ‡ç­¾</a></li>
            
        
            
                <li><a href="/categories/">åˆ†ç±»</a></li>
            
        
    </ul>
</div>

                    
                    

                    
                    

                    <!--è¯´æ˜æ˜¯æ–‡ç« posté¡µé¢-->
                    
                        <div class="post-main">
    

    
        
            
                <div class="post-main-title" style="text-align: center;">
                    å¦‚ä½•å®ç° MultiLossTrainer
                </div>
            
        
      
    

    

        
            <div class="post-head-meta-center">
        
                
                    <span>æœ€è¿‘æ›´æ–°ï¼š2025-11-22</span> 
                
                
                    
                        &nbsp; | &nbsp;
                    
                     <span>å­—æ•°æ€»è®¡ï¼š2k</span>
                
                
                    
                        &nbsp; | &nbsp;
                    
                    <span>é˜…è¯»ä¼°æ—¶ï¼š10åˆ†é’Ÿ</span>
                
                
                    
                        &nbsp; | &nbsp;
                    
                    <span id="busuanzi_container_page_pv">
                        é˜…è¯»é‡ï¼š<span id="busuanzi_value_page_pv"></span>æ¬¡
                    </span>
                
            </div>
    

    <div class="post-md">
        
            
                <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0-MultiLossTrainer"><span class="post-toc-text">å¦‚ä½•å®ç° MultiLossTrainer</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#MultiLossTrainer"><span class="post-toc-text">MultiLossTrainer</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#%E4%BB%85-eval-%E7%9A%84-MultiLossTrainer"><span class="post-toc-text">ä»… eval çš„ MultiLossTrainer</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#train-%E5%92%8C-eval-%E7%9A%84-MultiLossTrainer"><span class="post-toc-text">train å’Œ eval çš„ MultiLossTrainer</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Appendix"><span class="post-toc-text">Appendix</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#trainer-%E7%9A%84%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B"><span class="post-toc-text">trainer çš„è¿è¡Œæµç¨‹</span></a></li></ol></li></ol>
            
        
        <div class=".article-gallery"><h1 id="å¦‚ä½•å®ç°-MultiLossTrainer"><a href="#å¦‚ä½•å®ç°-MultiLossTrainer" class="headerlink" title="å¦‚ä½•å®ç° MultiLossTrainer"></a>å¦‚ä½•å®ç° MultiLossTrainer</h1><p><code>transformers</code> æ˜¯ç”± Huggingface å¼€å‘çš„å¤§æ¨¡å‹è®­ç»ƒåº“ï¼Œé›†æˆäº†ä¸»æµçš„å¤§æ¨¡å‹æ¡†æ¶å’Œè®­ç»ƒæ’ä»¶ã€‚ä½†æ˜¯é»˜è®¤è®¾ç½®ä¸­ï¼Œ <code>trainer</code> ä»…æ”¯æŒå• loss è®°å½•ï¼Œè€Œåœ¨å®éªŒè¿‡ç¨‹ä¸­ï¼Œå¾€å¾€æ¶‰åŠå¤š loss è®­ç»ƒï¼Œè¿™å°±éœ€è¦ <code>trainer</code> æ”¯æŒ Multiloss è®°å½•äº†ã€‚</p>
<p>æœ¬ç« èŠ‚å°†è¯¦ç»†ä»‹ç»å¦‚ä½•æ”¯æŒ Multilossã€‚</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(Env) IamMI@Server:~/Reps$ conda list | grep transformers</span><br><span class="line">transformers              4.47.0                   pypi_0    pypi</span><br></pre></td></tr></table></figure>

<h1 id="MultiLossTrainer"><a href="#MultiLossTrainer" class="headerlink" title="MultiLossTrainer"></a>MultiLossTrainer</h1><h2 id="ä»…-eval-çš„-MultiLossTrainer"><a href="#ä»…-eval-çš„-MultiLossTrainer" class="headerlink" title="ä»… eval çš„ MultiLossTrainer"></a>ä»… eval çš„ MultiLossTrainer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">eval_loop = <span class="variable language_">self</span>.prediction_loop <span class="keyword">if</span> <span class="variable language_">self</span>.args.use_legacy_prediction_loop <span class="keyword">else</span> <span class="variable language_">self</span>.evaluation_loop</span><br><span class="line">output = eval_loop(</span><br><span class="line">    eval_dataloader,</span><br><span class="line">    description=<span class="string">"Evaluation"</span>,</span><br><span class="line">    <span class="comment"># No point gathering the predictions if there are no metrics, otherwise we defer to</span></span><br><span class="line">    <span class="comment"># self.args.prediction_loss_only</span></span><br><span class="line">    prediction_loss_only=<span class="literal">True</span> <span class="keyword">if</span> <span class="variable language_">self</span>.compute_metrics <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">    ignore_keys=ignore_keys,</span><br><span class="line">    metric_key_prefix=metric_key_prefix,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>å¯ä»¥å…ˆä½¿ç”¨æ–­ç‚¹è°ƒè¯•ç­‰æ–¹å¼ï¼ŒæŸ¥çœ‹ <code>eval_loop</code> æ˜¯å“ªä¸€ä¸ªå‡½æ•°ï¼Œä¸‹é¢ä»¥ <code>self.evaluate_loop</code> ä¸ºä¾‹ã€‚ç¼–å†™ <code>MultiLossTrainer</code> ç»§æ‰¿è‡ª <code>Trainer</code>ï¼Œå¹¶é‡è½½</p>
<ul>
<li><p><code>evaluation_loop()</code><br>  æˆ‘å°†æ‰€æœ‰ç›¸å…³çš„ä¿®æ”¹éƒ½ä½¿ç”¨ ğŸ’¡ æ ‡æ³¨å‡ºæ¥äº†</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">evaluation_loop</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    dataloader,</span></span><br><span class="line"><span class="params">    description,</span></span><br><span class="line"><span class="params">    prediction_loss_only,</span></span><br><span class="line"><span class="params">    ignore_keys,</span></span><br><span class="line"><span class="params">    metric_key_prefix: <span class="built_in">str</span> = <span class="string">"eval"</span>,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line"></span><br><span class="line">    args = <span class="variable language_">self</span>.args</span><br><span class="line"></span><br><span class="line">    prediction_loss_only = prediction_loss_only <span class="keyword">if</span> prediction_loss_only <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> args.prediction_loss_only</span><br><span class="line"></span><br><span class="line">    model = <span class="variable language_">self</span>._wrap_model(<span class="variable language_">self</span>.model, training=<span class="literal">False</span>, dataloader=dataloader)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.accelerator._models) == <span class="number">0</span> <span class="keyword">and</span> model <span class="keyword">is</span> <span class="variable language_">self</span>.model:</span><br><span class="line">        start_time = time.time()</span><br><span class="line">        model = (</span><br><span class="line">            <span class="variable language_">self</span>.accelerator.prepare(model)</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.is_deepspeed_enabled <span class="keyword">or</span> <span class="variable language_">self</span>.is_fsdp_enabled</span><br><span class="line">            <span class="keyword">else</span> <span class="variable language_">self</span>.accelerator.prepare_model(model, evaluation_mode=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.model_preparation_time = <span class="built_in">round</span>(time.time() - start_time, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.is_fsdp_enabled:</span><br><span class="line">            <span class="variable language_">self</span>.model = model</span><br><span class="line"></span><br><span class="line">        <span class="comment"># for the rest of this function `model` is the outside model, whether it was wrapped or not</span></span><br><span class="line">        <span class="keyword">if</span> model <span class="keyword">is</span> <span class="keyword">not</span> <span class="variable language_">self</span>.model:</span><br><span class="line">            <span class="variable language_">self</span>.model_wrapped = model</span><br><span class="line"></span><br><span class="line">        <span class="comment"># backward compatibility</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.is_deepspeed_enabled:</span><br><span class="line">            <span class="variable language_">self</span>.deepspeed = <span class="variable language_">self</span>.model_wrapped</span><br><span class="line"></span><br><span class="line">    <span class="comment"># if full fp16 or bf16 eval is wanted and this ``evaluation`` or ``predict`` isn't called</span></span><br><span class="line">    <span class="comment"># while ``train`` is running, cast it to the right dtype first and then put on device</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.is_in_train:</span><br><span class="line">        <span class="keyword">if</span> args.fp16_full_eval:</span><br><span class="line">            model = model.to(dtype=torch.float16, device=args.device)</span><br><span class="line">        <span class="keyword">elif</span> args.bf16_full_eval:</span><br><span class="line">            model = model.to(dtype=torch.bfloat16, device=args.device)</span><br><span class="line"></span><br><span class="line">    batch_size = <span class="variable language_">self</span>.args.eval_batch_size</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">hasattr</span>(<span class="variable language_">self</span>.optimizer, <span class="string">"eval"</span>) <span class="keyword">and</span> <span class="built_in">callable</span>(<span class="variable language_">self</span>.optimizer.<span class="built_in">eval</span>):</span><br><span class="line">        <span class="variable language_">self</span>.optimizer.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="variable language_">self</span>.callback_handler.eval_dataloader = dataloader</span><br><span class="line">    <span class="comment"># Do this before wrapping.</span></span><br><span class="line">    eval_dataset = <span class="built_in">getattr</span>(dataloader, <span class="string">"dataset"</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.past_index &gt;= <span class="number">0</span>:</span><br><span class="line">        <span class="variable language_">self</span>._past = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize containers</span></span><br><span class="line">    all_losses = TorchLossContainer()<span class="comment"># ğŸ’¡å°† all_losses ä¿®æ”¹æˆè‡ªå®šä¹‰å®¹å™¨ï¼Œç”¨äºå‚¨å­˜å¤šä¸ª Loss</span></span><br><span class="line">    all_preds = EvalLoopContainer(<span class="variable language_">self</span>.args.eval_do_concat_batches, padding_index=-<span class="number">100</span>)</span><br><span class="line">    all_labels = EvalLoopContainer(<span class="variable language_">self</span>.args.eval_do_concat_batches, padding_index=-<span class="number">100</span>)</span><br><span class="line">    all_inputs = EvalLoopContainer(<span class="variable language_">self</span>.args.eval_do_concat_batches, padding_index=-<span class="number">100</span>)</span><br><span class="line">    <span class="comment"># all_lm_loss = EvalLoopContainer(self.args.eval_do_concat_batches, padding_index=-100)</span></span><br><span class="line">    <span class="comment"># all_align_loss = EvalLoopContainer(self.args.eval_do_concat_batches, padding_index=-100)</span></span><br><span class="line">    </span><br><span class="line">    metrics = <span class="literal">None</span></span><br><span class="line">    eval_set_kwargs = {}</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Will be useful when we have an iterable dataset so don't know its length.</span></span><br><span class="line">    observed_num_examples = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Main evaluation loop</span></span><br><span class="line">    <span class="keyword">for</span> step, inputs <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        <span class="comment"># Update the observed num examples</span></span><br><span class="line">        observed_batch_size = find_batch_size(inputs)</span><br><span class="line">        <span class="keyword">if</span> observed_batch_size <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            observed_num_examples += observed_batch_size</span><br><span class="line">            <span class="comment"># For batch samplers, batch_size is not known by the dataloader in advance.</span></span><br><span class="line">            <span class="keyword">if</span> batch_size <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                batch_size = observed_batch_size</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Prediction step</span></span><br><span class="line">        losses, logits, labels = <span class="variable language_">self</span>.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)</span><br><span class="line">        all_losses.add(losses)<span class="comment"># ğŸ’¡åŠ è½½è¾“å‡ºçš„å¤šä¸ª Loss</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        main_input_name = <span class="built_in">getattr</span>(<span class="variable language_">self</span>.model, <span class="string">"main_input_name"</span>, <span class="string">"input_ids"</span>)</span><br><span class="line">        inputs_decode = (</span><br><span class="line">            <span class="variable language_">self</span>._prepare_input(inputs[main_input_name]) <span class="keyword">if</span> <span class="string">"inputs"</span> <span class="keyword">in</span> args.include_for_metrics <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Update containers</span></span><br><span class="line">        <span class="comment"># ğŸ’¡æ³¨é‡Š losses çš„éƒ¨åˆ†ï¼Œåœ¨åç»­è¿›è¡Œå¤„ç†</span></span><br><span class="line">        <span class="comment"># if losses is not None:</span></span><br><span class="line">		    <span class="comment">#    losses = self.gather_function((losses.repeat(batch_size)))</span></span><br><span class="line">		    <span class="comment">#    all_losses.add(losses)</span></span><br><span class="line">        <span class="keyword">if</span> inputs_decode <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            inputs_decode = <span class="variable language_">self</span>.accelerator.pad_across_processes(inputs_decode, dim=<span class="number">1</span>, pad_index=-<span class="number">100</span>)</span><br><span class="line">            inputs_decode = <span class="variable language_">self</span>.gather_function((inputs_decode))</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.args.batch_eval_metrics <span class="keyword">or</span> description == <span class="string">"Prediction"</span>:</span><br><span class="line">                all_inputs.add(inputs_decode)</span><br><span class="line">        <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># Pad labels here, preparing for preprocess_logits_for_metrics in next logits block.</span></span><br><span class="line">            labels = <span class="variable language_">self</span>.accelerator.pad_across_processes(labels, dim=<span class="number">1</span>, pad_index=-<span class="number">100</span>)</span><br><span class="line">        <span class="keyword">if</span> logits <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            logits = <span class="variable language_">self</span>.accelerator.pad_across_processes(logits, dim=<span class="number">1</span>, pad_index=-<span class="number">100</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.preprocess_logits_for_metrics <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                logits = <span class="variable language_">self</span>.preprocess_logits_for_metrics(logits, labels)</span><br><span class="line">            logits = <span class="variable language_">self</span>.gather_function((logits))</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.args.batch_eval_metrics <span class="keyword">or</span> description == <span class="string">"Prediction"</span>:</span><br><span class="line">                all_preds.add(logits)</span><br><span class="line">        <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            labels = <span class="variable language_">self</span>.gather_function((labels))</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.args.batch_eval_metrics <span class="keyword">or</span> description == <span class="string">"Prediction"</span>:</span><br><span class="line">                all_labels.add(labels)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.control = <span class="variable language_">self</span>.callback_handler.on_prediction_step(args, <span class="variable language_">self</span>.state, <span class="variable language_">self</span>.control)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Gather all tensors and put them back on the CPU if we have done enough accumulation steps.</span></span><br><span class="line">        <span class="keyword">if</span> args.eval_accumulation_steps <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> (step + <span class="number">1</span>) % args.eval_accumulation_steps == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># all_losses.to_cpu_and_numpy() # ğŸ’¡æ³¨é”€ all_losses</span></span><br><span class="line">            all_preds.to_cpu_and_numpy()</span><br><span class="line">            all_labels.to_cpu_and_numpy()</span><br><span class="line">            all_inputs.to_cpu_and_numpy()</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">del</span> losses, logits, labels, inputs</span><br><span class="line">            torch.cuda.empty_cache()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># After all calls to `.gather_function`, reset to `gather_for_metrics`:</span></span><br><span class="line">    <span class="variable language_">self</span>.gather_function = <span class="variable language_">self</span>.accelerator.gather_for_metrics</span><br><span class="line">    <span class="keyword">if</span> args.past_index <span class="keyword">and</span> <span class="built_in">hasattr</span>(<span class="variable language_">self</span>, <span class="string">"_past"</span>):</span><br><span class="line">        <span class="comment"># Clean the state at the end of the evaluation loop</span></span><br><span class="line">        <span class="built_in">delattr</span>(<span class="variable language_">self</span>, <span class="string">"_past"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Gather all remaining tensors and put them back on the CPU</span></span><br><span class="line">    <span class="comment"># all_losses = all_losses.get_arrays() # ğŸ’¡æ³¨é”€ all_losses</span></span><br><span class="line">    all_preds = all_preds.get_arrays()</span><br><span class="line">    all_labels = all_labels.get_arrays()</span><br><span class="line">    all_inputs = all_inputs.get_arrays()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Number of samples</span></span><br><span class="line">    <span class="keyword">if</span> has_length(eval_dataset):</span><br><span class="line">        num_samples = <span class="built_in">len</span>(eval_dataset)</span><br><span class="line">    <span class="comment"># The instance check is weird and does not actually check for the type, but whether the dataset has the right</span></span><br><span class="line">    <span class="comment"># methods. Therefore we need to make sure it also has the attribute.</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(eval_dataset, IterableDatasetShard) <span class="keyword">and</span> <span class="built_in">getattr</span>(eval_dataset, <span class="string">"num_examples"</span>, <span class="number">0</span>) &gt; <span class="number">0</span>:</span><br><span class="line">        num_samples = eval_dataset.num_examples</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> has_length(dataloader):</span><br><span class="line">            num_samples = <span class="variable language_">self</span>.num_examples(dataloader)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># both len(dataloader.dataset) and len(dataloader) fail</span></span><br><span class="line">            num_samples = observed_num_examples</span><br><span class="line">    <span class="keyword">if</span> num_samples == <span class="number">0</span> <span class="keyword">and</span> observed_num_examples &gt; <span class="number">0</span>:</span><br><span class="line">        num_samples = observed_num_examples</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Metrics!</span></span><br><span class="line">    <span class="comment"># ğŸ’¡è¿™ä¸ªéƒ¨åˆ†åŸæœ¬æ˜¯è®¡ç®— metricsï¼Œå› ä¸ºæœ¬äººå¹¶ä¸éœ€è¦ï¼Œæ•…åˆ é™¤ï¼Œæœ‰éœ€æ±‚è€…å¯ä»¥ä¿ç•™  </span></span><br><span class="line">    metrics = {}</span><br><span class="line"></span><br><span class="line">    <span class="comment"># To be JSON-serializable, we need to remove numpy types or zero-d tensors</span></span><br><span class="line">    metrics = denumpify_detensorize(metrics)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># loss</span></span><br><span class="line">    <span class="keyword">for</span> key, value <span class="keyword">in</span> all_losses.get().items():</span><br><span class="line">        metrics[<span class="string">f"<span class="subst">{metric_key_prefix}</span>_<span class="subst">{key}</span>"</span>] = value</span><br><span class="line">    <span class="comment"># ğŸ’¡å°†åŸå…ˆçš„è®°å½•ï¼Œè¿›è¡Œä¿®æ”¹</span></span><br><span class="line">    <span class="comment"># if isinstance(all_losses, list) and all_losses:</span></span><br><span class="line">    <span class="comment">#     metrics[f"{metric_key_prefix}_loss"] = np.concatenate(all_losses).mean().item()</span></span><br><span class="line">    <span class="comment"># elif isinstance(all_losses, np.ndarray):</span></span><br><span class="line">    <span class="comment">#     metrics[f"{metric_key_prefix}_loss"] = all_losses.mean().item()    </span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">hasattr</span>(<span class="variable language_">self</span>, <span class="string">"jit_compilation_time"</span>):</span><br><span class="line">        metrics[<span class="string">f"<span class="subst">{metric_key_prefix}</span>_jit_compilation_time"</span>] = <span class="variable language_">self</span>.jit_compilation_time</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">hasattr</span>(<span class="variable language_">self</span>, <span class="string">"model_preparation_time"</span>):</span><br><span class="line">        metrics[<span class="string">f"<span class="subst">{metric_key_prefix}</span>_model_preparation_time"</span>] = <span class="variable language_">self</span>.model_preparation_time</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Prefix all keys with metric_key_prefix + '_'</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> <span class="built_in">list</span>(metrics.keys()):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> key.startswith(<span class="string">f"<span class="subst">{metric_key_prefix}</span>_"</span>):</span><br><span class="line">            metrics[<span class="string">f"<span class="subst">{metric_key_prefix}</span>_<span class="subst">{key}</span>"</span>] = metrics.pop(key)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> EvalLoopOutput(predictions=all_preds, label_ids=all_labels, metrics=metrics, num_samples=num_samples)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<p>æ¥ç€æ˜¯è‡ªå®šä¹‰ Containerï¼Œç”¨äºå­˜å‚¨å¤šä¸ª Loss æ•°æ®</p>
<ul>
<li><p><code>TorchLossContainer</code></p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TorchLossContainer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, device=<span class="string">'cpu'</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.loss_dict = {}</span><br><span class="line">        <span class="variable language_">self</span>.count_dict = {}</span><br><span class="line">        <span class="variable language_">self</span>.device = device</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">self, loss_dict</span>):</span><br><span class="line">        <span class="keyword">for</span> key, value <span class="keyword">in</span> loss_dict.items():</span><br><span class="line">            <span class="keyword">if</span> key <span class="keyword">not</span> <span class="keyword">in</span> <span class="variable language_">self</span>.loss_dict:</span><br><span class="line">                <span class="variable language_">self</span>.loss_dict[key] = []</span><br><span class="line">            <span class="variable language_">self</span>.loss_dict[key].append(value.cpu())</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get</span>(<span class="params">self</span>):     </span><br><span class="line">        loss_dict = {}   </span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> <span class="variable language_">self</span>.loss_dict.keys():</span><br><span class="line">            loss_dict[key] = np.array(<span class="variable language_">self</span>.loss_dict[key]).mean()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> loss_dict</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.loss_dict.clear()</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<div class="admonition note"><p>ğŸ’¡ æ­¤æ—¶è¾“å‡ºçš„ losses å·²ç»ä¸æ˜¯ torch.tensorï¼Œè€Œæ˜¯ dictï¼Œé‡Œé¢è®°å½•äº†å¤šç§ lossï¼Œæ‰€ä»¥ <code>prediction_step</code> å°±éœ€è¦è¾“å‡ºä¸€ä¸ªåŒ…å«å¤šç§ loss çš„ dict</p>
</div>

<hr>
<ul>
<li><p><code>prediction_step()</code></p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">prediction_step</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    model,</span></span><br><span class="line"><span class="params">    inputs,</span></span><br><span class="line"><span class="params">    prediction_loss_only,</span></span><br><span class="line"><span class="params">    ignore_keys = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line"></span><br><span class="line">    has_labels = <span class="literal">False</span> <span class="keyword">if</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.label_names) == <span class="number">0</span> <span class="keyword">else</span> <span class="built_in">all</span>(inputs.get(k) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">for</span> k <span class="keyword">in</span> <span class="variable language_">self</span>.label_names)</span><br><span class="line">    <span class="comment"># For CLIP-like models capable of returning loss values.</span></span><br><span class="line">    <span class="comment"># If `return_loss` is not specified or being `None` in `inputs`, we check if the default value of `return_loss`</span></span><br><span class="line">    <span class="comment"># is `True` in `model.forward`.</span></span><br><span class="line">    return_loss = inputs.get(<span class="string">"return_loss"</span>, <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">if</span> return_loss <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        return_loss = <span class="variable language_">self</span>.can_return_loss</span><br><span class="line">    loss_without_labels = <span class="literal">True</span> <span class="keyword">if</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.label_names) == <span class="number">0</span> <span class="keyword">and</span> return_loss <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    inputs = <span class="variable language_">self</span>._prepare_inputs(inputs)</span><br><span class="line">    <span class="keyword">if</span> ignore_keys <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(<span class="variable language_">self</span>.model, <span class="string">"config"</span>):</span><br><span class="line">            ignore_keys = <span class="built_in">getattr</span>(<span class="variable language_">self</span>.model.config, <span class="string">"keys_to_ignore_at_inference"</span>, [])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            ignore_keys = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># labels may be popped when computing the loss (label smoothing for instance) so we grab them first.</span></span><br><span class="line">    <span class="keyword">if</span> has_labels <span class="keyword">or</span> loss_without_labels:</span><br><span class="line">        labels = nested_detach(<span class="built_in">tuple</span>(inputs.get(name) <span class="keyword">for</span> name <span class="keyword">in</span> <span class="variable language_">self</span>.label_names))</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(labels) == <span class="number">1</span>:</span><br><span class="line">            labels = labels[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        labels = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">if</span> has_labels <span class="keyword">or</span> loss_without_labels:</span><br><span class="line">            <span class="keyword">with</span> <span class="variable language_">self</span>.compute_loss_context_manager():</span><br><span class="line">                loss, outputs = <span class="variable language_">self</span>.compute_loss(model, inputs, return_outputs=<span class="literal">True</span>)</span><br><span class="line">            loss = loss.mean().detach()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(outputs, <span class="built_in">dict</span>):</span><br><span class="line">                logits = <span class="built_in">tuple</span>(v <span class="keyword">for</span> k, v <span class="keyword">in</span> outputs.items() <span class="keyword">if</span> k <span class="keyword">not</span> <span class="keyword">in</span> ignore_keys + [<span class="string">"loss"</span>])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                logits = outputs[<span class="number">1</span>:]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            loss = <span class="literal">None</span></span><br><span class="line">            <span class="keyword">with</span> <span class="variable language_">self</span>.compute_loss_context_manager():</span><br><span class="line">                outputs = model(**inputs)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(outputs, <span class="built_in">dict</span>):</span><br><span class="line">                logits = <span class="built_in">tuple</span>(v <span class="keyword">for</span> k, v <span class="keyword">in</span> outputs.items() <span class="keyword">if</span> k <span class="keyword">not</span> <span class="keyword">in</span> ignore_keys)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                logits = outputs</span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span> this needs to be fixed and made cleaner later.</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.args.past_index &gt;= <span class="number">0</span>:</span><br><span class="line">                <span class="variable language_">self</span>._past = outputs[<span class="variable language_">self</span>.args.past_index - <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> prediction_loss_only:</span><br><span class="line">        losses = {</span><br><span class="line">            <span class="string">"loss"</span>: loss,</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(outputs, <span class="built_in">tuple</span>) <span class="keyword">and</span> outputs[<span class="number">1</span>].dim()==<span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">hasattr</span>(model, <span class="string">"loss_name"</span>):</span><br><span class="line">                <span class="keyword">for</span> los, name <span class="keyword">in</span> <span class="built_in">zip</span>(outputs[<span class="number">1</span>:], model.loss_name):</span><br><span class="line">                    <span class="keyword">assert</span> los.dim()==<span class="number">0</span></span><br><span class="line">                    losses.update({</span><br><span class="line">                        <span class="string">f"<span class="subst">{name}</span>_loss"</span>: los,</span><br><span class="line">                    })</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                losses.update({</span><br><span class="line">                    <span class="string">"lm_loss"</span>: outputs[<span class="number">1</span>],</span><br><span class="line">                    <span class="string">"align_loss"</span>: outputs[<span class="number">2</span>] </span><br><span class="line">                })</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(outputs, <span class="built_in">dict</span>) <span class="keyword">and</span> (<span class="string">"additional_losses"</span> <span class="keyword">in</span> outputs.keys()):</span><br><span class="line">            losses.update(outputs.additional_losses)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">return</span> (losses, <span class="literal">None</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    logits = nested_detach(logits)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(logits) == <span class="number">1</span>:</span><br><span class="line">        logits = logits[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (losses, logits, labels)</span><br></pre></td></tr></table></figure></li>
</ul>
<p>å¯ä»¥çœ‹åˆ°ï¼Œè¿™é‡Œæ¶‰åŠäº†ä¸¤ä¸ªé‡è¦æ¦‚å¿µ</p>
<ol>
<li><p><em><strong>model.forward() çš„è¿”å›å€¼æ˜¯ä»€ä¹ˆï¼Ÿ</strong></em></p>
<p> è¿™é‡Œä»¥ align_loss + lm_loss ä¸ºä¾‹ï¼Œåˆ™ä»¿ç…§ transformers çš„æ¡†æ¶</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> return_dict:</span><br><span class="line">    <span class="keyword">return</span> ((loss, lm_loss.detach(), align_loss.detach()) + outputs) <span class="keyword">if</span> loss <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> outputs</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> CausalLMOutputWithCrossAttentions(</span><br><span class="line">    loss=loss,</span><br><span class="line">    logits=lm_logits,</span><br><span class="line">    past_key_values=presents <span class="keyword">if</span> use_cache <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">    hidden_states=all_hidden_states,</span><br><span class="line">    attentions=all_attentions,</span><br><span class="line">    additional_losses={</span><br><span class="line">        <span class="string">"lm_loss"</span>: lm_loss.detach(),</span><br><span class="line">        <span class="string">"align_loss"</span>: align_loss.detach()</span><br><span class="line">    }</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</li>
<li><p><em><strong>å‡å¦‚ <code>return_dict=False</code>ï¼Œ <code>prediction_step()</code> åˆè¯¥å¦‚ä½•èµ‹äºˆ key å‘¢ï¼Ÿ</strong></em></p>
<p> æˆ‘ä»¬ä¸º model åŠ å…¥ <code>self.loss_name</code> </p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.loss_name = [<span class="string">"lm"</span>, <span class="string">"align"</span>]</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h2 id="train-å’Œ-eval-çš„-MultiLossTrainer"><a href="#train-å’Œ-eval-çš„-MultiLossTrainer" class="headerlink" title="train å’Œ eval çš„ MultiLossTrainer"></a>train å’Œ eval çš„ MultiLossTrainer</h2><p>train çš„éƒ¨åˆ†æ¯” eval å¤æ‚å¾—å¤šï¼Œéœ€è¦ä¿®æ”¹çš„éƒ¨åˆ†ä¹Ÿæ›´å¤šï¼Œè¿™é‡Œå°±ä¸å®ç°äº†ï¼Œæ„Ÿå…´è¶£è€…å¯ä»¥æŸ¥çœ‹ <em><strong>Appendix</strong></em></p>
<h1 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h1><h2 id="trainer-çš„è¿è¡Œæµç¨‹"><a href="#trainer-çš„è¿è¡Œæµç¨‹" class="headerlink" title="trainer çš„è¿è¡Œæµç¨‹"></a>trainer çš„è¿è¡Œæµç¨‹</h2><p>ä¸‹é¢åˆ—ä¸¾å‡º <code>trainer</code> çš„è®­ç»ƒæµç¨‹ï¼Œä»…æŒ‡å‡ºå…³é”®å‡½æ•°ã€‚</p>
<pre class="mermaid">flowchart LR
    subgraph node3["training_step( )"]
        node4["forward and compute loss"]
    end
    subgraph node5["_maybe_log_save_evaluate( )"]
        node6["training log"] --&gt; node7["evaluate and log"]
    end
    subgraph node2["_inner_training_loop( )"]
        node3 -- "training_loss" --&gt; node5
    end
    subgraph train["train( )"]
        node1["prepare"] --&gt; node2["_inner_training_loop( )"]
    end</pre>

<ul>
<li><p>å‡å¦‚ training é˜¶æ®µä¹Ÿéœ€è¦æ”¯æŒ Multilossï¼Œå°±éœ€è¦ä» <code>_inner_training_loop()</code> å¼€å§‹æ”¹ï¼Œä¿è¯ <code>training_step()</code> çš„è¾“å‡ºåŒ…å«å¤šä¸ª lossï¼ˆé»˜è®¤ä»…è¾“å‡ºä¸€ä¸ªï¼‰</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> context():</span><br><span class="line">    tr_loss_step = <span class="variable language_">self</span>.training_step(model, inputs, num_items_in_batch)</span><br><span class="line">    <span class="comment"># è¿™é‡Œä»…ä»…è¿”å›äº† tr_loss_step å•ä¸ªloss</span></span><br></pre></td></tr></table></figure>
<p>  å…¶æ¬¡ï¼Œ <code>_maybe_log_save_evaluate()</code> çš„ä¼ å‚ä¸­ä¹Ÿéœ€è¦æ”¯æŒä¼ å…¥å¤šä¸ª lossï¼ˆé»˜è®¤ä»…ä¼ å…¥ tr_lossï¼‰</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä»…ä¼ å…¥ tr_loss</span></span><br><span class="line"><span class="variable language_">self</span>._maybe_log_save_evaluate(</span><br><span class="line">    tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>  ä»¥åŠ</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä»…å¤„ç† tr_loss</span></span><br><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.control.should_log <span class="keyword">and</span> <span class="variable language_">self</span>.state.global_step &gt; <span class="variable language_">self</span>._globalstep_last_logged:</span><br><span class="line">    <span class="keyword">if</span> is_torch_xla_available():</span><br><span class="line">        xm.mark_step()</span><br><span class="line"></span><br><span class="line">    logs: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">float</span>] = {}</span><br><span class="line"></span><br><span class="line">    <span class="comment"># all_gather + mean() to get average loss over all processes</span></span><br><span class="line">    tr_loss_scalar = <span class="variable language_">self</span>._nested_gather(tr_loss).mean().item()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># reset tr_loss to zero</span></span><br><span class="line">    tr_loss -= tr_loss</span><br><span class="line"></span><br><span class="line">    logs[<span class="string">"loss"</span>] = <span class="built_in">round</span>(tr_loss_scalar / (<span class="variable language_">self</span>.state.global_step - <span class="variable language_">self</span>._globalstep_last_logged), <span class="number">4</span>)</span><br><span class="line">    <span class="keyword">if</span> grad_norm <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        logs[<span class="string">"grad_norm"</span>] = grad_norm.detach().item() <span class="keyword">if</span> <span class="built_in">isinstance</span>(grad_norm, torch.Tensor) <span class="keyword">else</span> grad_norm</span><br><span class="line">    logs[<span class="string">"learning_rate"</span>] = <span class="variable language_">self</span>._get_learning_rate()</span><br><span class="line"></span><br><span class="line">    <span class="variable language_">self</span>._total_loss_scalar += tr_loss_scalar</span><br><span class="line">    <span class="variable language_">self</span>._globalstep_last_logged = <span class="variable language_">self</span>.state.global_step</span><br><span class="line">    <span class="variable language_">self</span>.store_flos()</span><br><span class="line"></span><br><span class="line">    <span class="variable language_">self</span>.log(logs, start_time)</span><br></pre></td></tr></table></figure>
</li>
<li><p>å‡å¦‚ evaluate é˜¶æ®µéœ€è¦æ”¯æŒ Multilossï¼Œæ”¹åŠ¨ç›¸å¯¹è¾ƒå°‘ï¼Œåªéœ€è¦å…³æ³¨ <code>_maybe_log_save_evaluate._evaluate.evaluate</code></p>
  <pre class="mermaid">    flowchart LR
      subgraph node0["evaluate( )"]
          node1["eval_loop( )"] -- "output" --&gt; node2["self.log(output.metrics)"]
      end</pre>
<p>  åªéœ€è¦ä¿è¯ <code>eval_loop()</code> è¾“å‡ºçš„ output.metrics å·²ç»è®°å½•äº†å¤šä¸ª loss çš„ä¿¡æ¯ã€‚</p>
</li>
</ul>
</div>
    </div>

    <div class="post-meta">
        <i>
        
            <span>2025-11-22</span>
            
                <span>è¯¥ç¯‡æ–‡ç« è¢« IamMI</span>
            
            
             
                <span>å½’ä¸ºåˆ†ç±»:
                    
                    
                        <a href='/categories/transformers-%E8%BF%9B%E9%98%B6%E6%95%99%E7%A8%8B/'>
                            transformers-è¿›é˜¶æ•™ç¨‹
                        </a>
                    
                </span>
            
        
        </i>
    </div>
    <br>
    
    
        
            
    
            <div class="post-footer-pre-next">
                

                
                    <span class="post-footer-pre-next-last-span-right">ä¸‹ä¸€ç¯‡ï¼š<a href="/2025/11/21/Preliminaries/">Preliminaries</a>
                    </span>
                
            </div>
    
        
    

    
        

     
</div>




                    

                    <div class="footer">
    
        <span> 
            Â© 1949-2025 China 

            
                

            
        </span>
       
    
</div>



<!--è¿™æ˜¯æŒ‡ä¸€æ¡çº¿å¾€ä¸‹çš„å†…å®¹-->
<div class="footer-last">
    
            <span>We Must Know, We Will Know.</span>
            
                <span class="footer-last-span-right"><i>æœ¬ç«™ç”±<a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/index.html">Hexo</a>é©±åŠ¨ï½œä½¿ç”¨<a target="_blank" rel="noopener" href="https://github.com/HiNinoJay/hexo-theme-A4">Hexo-theme-A4</a>ä¸»é¢˜</i></span>
            
    
</div>


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>

    <!--ç›®å½•-->
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.7.2/jquery.min.js" type="text/javascript" ></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js" type="text/javascript" ></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tocify/1.9.0/javascripts/jquery.tocify.min.js" type="text/javascript" ></script>
        
<script src="/js/toc.js"></script>

    

    
<script src="/js/randomHeaderContent.js"></script>

    <!--å›åˆ°é¡¶éƒ¨æŒ‰é’®-->
    
        
<script src="/js/returnToTop.js"></script>

    

    
        
<script src="/js/returnToLastPage.js"></script>

    





<script src="/js/lightgallery/lightgallery.umd.min.js"></script>



<script src="/js/lightgallery/plugins/lg-thumbnail.umd.min.js"></script>



<script src="/js/lightgallery/plugins/lg-fullscreen.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-autoplay.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-zoom.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-rotate.umd.min.js"></script>


<script src="/js/lightgallery/plugins/lg-paper.umd.min.js"></script>




<script type="text/javascript">
     
    if (typeof lightGallery !== "undefined") {
        var options1 = {
            selector: '.gallery-item',
            plugins: [lgThumbnail, lgFullscreen, lgAutoplay, lgZoom, lgRotate, lgPager], // å¯ç”¨æ’ä»¶
            thumbnail: true,          // æ˜¾ç¤ºç¼©ç•¥å›¾
            zoom: true,               // å¯ç”¨ç¼©æ”¾åŠŸ
            rotate: true,             // å¯ç”¨æ—‹è½¬åŠŸèƒ½èƒ½
            autoplay: true,        // å¯ç”¨è‡ªåŠ¨æ’­æ”¾åŠŸèƒ½
            fullScreen: true,      // å¯ç”¨å…¨å±åŠŸèƒ½
            pager: false, //é¡µç ,
            zoomFromOrigin: true,   // ä»åŸå§‹ä½ç½®ç¼©æ”¾
            actualSize: true,       // å¯ç”¨æŸ¥çœ‹å®é™…å¤§å°çš„åŠŸèƒ½
            enableZoomAfter: 300,    // å»¶è¿Ÿç¼©æ”¾ï¼Œç¡®ä¿å›¾ç‰‡åŠ è½½å®Œæˆåå¯ç¼©æ”¾
        };
        lightGallery(document.getElementsByClassName('.article-gallery')[0], options1); // ä¿®å¤é€‰æ‹©å™¨
    }
    
</script>


    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> 

                </div>
            
            
                <!-- å›åˆ°é¡¶éƒ¨çš„æŒ‰é’®-->
                <div class="progress-wrap shadow-drop-2-bottom">
                    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
                        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
                    </svg>
                </div>
            
            
                <!-- è¿”å›çš„æŒ‰é’®-->
                <div class="return-to-last-progress-wrap shadow-drop-2-bottom">
                    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
                        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98"/>
                    </svg>
                </div>
            
    </body>
</html>
<script src="/js/emojiHandler.js"></script>
<script>
    document.addEventListener('DOMContentLoaded', () => {
        wrapEmojis('.paper');
    });
</script>
